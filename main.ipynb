{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-11-21T18:35:06.433268Z","iopub.execute_input":"2023-11-21T18:35:06.434005Z","iopub.status.idle":"2023-11-21T18:35:21.666204Z","shell.execute_reply.started":"2023-11-21T18:35:06.433952Z","shell.execute_reply":"2023-11-21T18:35:21.664815Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.57.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.9.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (68.1.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.34.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.0.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Activation\nfrom tensorflow.keras.optimizers import RMSprop\n\n# Getting the file that we are going to do the training with\n# We are going to use TensorFlow to download it\nfilepath = tf.keras.utils.get_file(\"shakespeare.txt\", 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\ntext = open(filepath, 'rb').read().decode(encoding='utf-8').lower()\n\n# Converting the binary data into a human-readable Unicode\ntext = text[300000:800000]\n\n# Creates a sorted list of unique characters from the text\ncharacters = sorted(set(text))\n\n# Creates dictionaries to map characters to indices and indices to characters\nchar_to_index = dict((c, i) for i, c in enumerate(characters))\nindex_to_char = dict((i, c) for i, c in enumerate(characters))\n\n# Sets the sequence length and step size for creating training data\nSEQ_LENGTH = 40\nSTEP_SIZE = 3\n\n# Creates training data by generating sequences of length SEQ_LENGTH with a step size of STEP_SIZE\nsentences = []\nnext_characters = []\n\nfor i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n    sentences.append(text[i:i + SEQ_LENGTH])\n    next_characters.append(text[i + SEQ_LENGTH])\n\n# Convert the training data to numpy\nx = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\ny = np.zeros((len(sentences), len(characters)), dtype=bool)\n\nfor i, sentence in enumerate(sentences):\n    for t, character in enumerate(sentence):\n        # Converts the training data into numpy arrays suitable for training a neural network.\n        # x is a 3D array representing one-hot encoded input sequences.\n        # y is a 2D array representing one-hot encoded target characters.\n        x[i, t, char_to_index[character]] = 1\n    y[i, char_to_index[next_characters[i]]] = 1\n\n# Building the neural network\nmodel = Sequential()\n# The input shape should be a tuple (SEQ_LENGTH, len(characters))\nmodel.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n\nmodel.add(Dense(len(characters)))\nmodel.add(Activation('softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\nmodel.fit(x, y, batch_size=256, epochs=4)\nmodel.save('textgenerator.model')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T19:12:25.614858Z","iopub.execute_input":"2023-11-21T19:12:25.615317Z","iopub.status.idle":"2023-11-21T19:17:58.504851Z","shell.execute_reply.started":"2023-11-21T19:12:25.615286Z","shell.execute_reply":"2023-11-21T19:17:58.503317Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Epoch 1/4\n651/651 [==============================] - 82s 121ms/step - loss: 2.7312\nEpoch 2/4\n651/651 [==============================] - 79s 122ms/step - loss: 2.3364\nEpoch 3/4\n651/651 [==============================] - 80s 122ms/step - loss: 2.2256\nEpoch 4/4\n651/651 [==============================] - 80s 123ms/step - loss: 2.1518\n","output_type":"stream"}]},{"cell_type":"code","source":"def sample(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text(length, temperature):\n    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n    generated = ''\n    sentence = text[start_index:start_index + SEQ_LENGTH]\n    generated += sentence\n    for i in range(length):\n        x = np.zeros((1, SEQ_LENGTH, len(characters)))  # Fix the shape of the array\n        for t, character in enumerate(sentence):\n            x[0, t, char_to_index[character]] = 1  # Fix the indexing of the array\n        predictions = model.predict(x, verbose=0)[0]\n        next_index = sample(predictions, temperature)  # Fix the typo in 'predictions'\n        next_character = index_to_char[next_index]\n        generated += next_character\n        sentence = sentence[1:] + next_character\n    return generated\n\nprint('-----0.2-----')\nprint(generate_text(300, 0.2))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T19:28:46.700208Z","iopub.execute_input":"2023-11-21T19:28:46.700730Z","iopub.status.idle":"2023-11-21T19:29:10.623540Z","shell.execute_reply.started":"2023-11-21T19:28:46.700686Z","shell.execute_reply":"2023-11-21T19:29:10.622745Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"-----0.2-----\ns a sea, for it is now the\nsky: betwixt the sore the here the store the here the beart the sore the sore the will the sare the will stere the sear and the sere the seare the with the sher the wist the seard the sear the shat the seath the rore the wist in the the sore the shere the sore the the the sore the here the fore the shen the the \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}